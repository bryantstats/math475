---
title: "White Noise and Random Walks"
format: 
  beamer
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

# White Noise

-   $y_t$ is a white-noise process (series) if $y_1$, $y_2$,...$y_t$... are i.i.d zero mean random variables from a certain distribution (usually normal)


# Example

```{r}
set.seed(30)
y <- ts(rnorm(100))
library(ggfortify)
autoplot(y) + ggtitle("White noise of Standard Normal Distribution")
```

# Example

```{r}
set.seed(30)

y = sample(c(-1, 1), 100, replace = TRUE)

y <- ts(y)
library(ggfortify)
autoplot(y) + ggtitle("White noise of Tossing a Coin")
```

# Correlogram

- Autocorrelation lag with lag k is the the correlation between the time series $y_t$ and $y_{t-k}$

- Autocorrelation lag with lag 0 is always 1

- The Correlogram is the plot of the autocorrelations for values of lag k = 0, 1, 2,...

# Correlogram a white noise

- Correlogram of a white noise

```{r}
y = ts(rnorm(100))
acf(y)
```

# Correlogram a white noise

```{r}
set.seed(30)

y = sample(c(-1, 1), 100, replace = TRUE)

y <- ts(y)

acf(y)

```

# 

```{=tex}
\begin{center}
\Huge Random Walk
\end{center}
```

# Random Walk

-   A time series $y_t$ is called a random walk if

    $$y_{t} =  y_{t-1} +  \epsilon_t,$$

    where $\epsilon_t$ is a white-noise

-   A random walk can be written as

$$
y_t = y_0 + \epsilon_1 + \epsilon_2 +...+\epsilon_t
$$

# Random Walk with drift

-   A time series $y_t$ is called a random walk if

    $$y_{t} =  y_{t-1} +  d + \epsilon_t,$$

    where $\epsilon_t$ is a white-noise

-   A random walk can be written as

$$
y_t = y_0 + dt + \epsilon_1 + \epsilon_2 +...+\epsilon_t
$$

# Example

```{r}
set.seed(1)
n <- 5
ct = sample(c(-1, 1), n, TRUE)
x <- cumsum(c(0,ct))
autoplot(ts(x))
```

# Example

```{r}
set.seed(1)
n <- 1000
ct = c(0, sample(c(-1, 1), n, TRUE))
x <- cumsum(ct)
autoplot(ts(x))
```

# Example

```{r}
set.seed(3000)
n = 100
c <- rnorm(n)
y_0 = 0
y = c(y_0, 2:n)

for (i in 2:n)
{
  y[i] = y[i-1]+c[i]
}

library(ggfortify)
library(latex2exp)

autoplot(ts(y)) + ggtitle("A random walk: ")
```

# Example

```{r}
set.seed(30)
n = 1000
c <- rnorm(n, sd = 20)
y_0 = 0
drift = 5

y = c(y_0, 2:n)

for (i in 2:n)
{
  y[i] = drift  + y[i-1]+c[i]
}

library(ggfortify)
library(latex2exp)

autoplot(ts(y)) + ggtitle(paste0("A random walk with drift being ", drift))
```

# 

```{=tex}
\begin{center}
\Huge Forecasting with Random Walks
\end{center}
```

# The Correlogram

- Autocorrelation lag with lag k is the the correlation between the time series $y_t$ and $y_{t-k}$

- Autocorrelation lag with lag 0 is always 1

- The Correlogram is the plot of the autocorrelations for values of lag k = 0, 1, 2,...

# The Correlogram - Example

- Correlogram of a white noise

```{r}
y = ts(rnorm(100))
acf(y)
```

# The Correlogram - Example

- Correlogram of a time series with trend

- Usually a trend in the data will show in the correlogram as a slow decay in the autocorrelation

```{r}
y = ts(c(1:100)+rnorm(100))
acf(y)
```

# The Correlogram - Example

```{r}
y = ts(cos(c(1:100))+rnorm(100))
acf(y)
```

# The Correlogram of Random Walks

```{r}
n = 100
error_mean = 0
c <- rnorm(n, mean = error_mean, sd = 30)
y_0 = 0
y = c(y_0, 2:n)

for (i in 2:n)
{
  y[i] = y[i-1]+c[i]
}

library(ggfortify)
library(latex2exp)

acf(y)
```

# Differencing Time Series

```{r}
n = 100
error_mean = 0
drift = 100
c <- rnorm(n, mean = error_mean, sd = 30)
y_0 = 0
y = c(y_0, 2:n)

for (i in 2:n)
{
  y[i] = drift+ y[i-1]+c[i]
}

y = ts(y)

plot(diff(ts(y)))

```


# The Correlogram of Random Walks

```{r}
n = 100
error_mean = 0
drift = 40
c <- rnorm(n, mean = error_mean, sd = 30)
y_0 = 0
y = c(y_0, 2:n)

for (i in 2:n)
{
  y[i] = drift+ y[i-1]+c[i]
}

library(ggfortify)
library(latex2exp)

acf(diff(y))
```


# Random Walks and Stocks

```{r}
library(quantmod)
getSymbols('MSFT', src='yahoo')
y = Ad(MSFT[index(MSFT)>"2023-01-01",])

plot(y)
plot(diff(y))
```

#

```{r}
n = 100
error_mean = 0
drift = 40
c <- rnorm(n, mean = error_mean, sd = 30)
y_0 = 0
y = c(y_0, 2:n)

for (i in 2:n)
{
  y[i] = drift+ y[i-1]+c[i]
}

y = ts(y)

```

# Estimate the random walk model

For a given time series y we can fit the random walk model with a drift by 

- first differencing the data, 

- then fitting the white noise (WN) model to the differenced data using the arima() command with the order = c(0, 0, 0)) argument.

- The arima() command displays information or output about the fitted model. Under the Coefficients: heading is the estimated drift variable, named the intercept. Its approximate standard error (or s.e.) is provided directly below it. The variance of the WN part of the model is also estimated under the label sigma^2.


#

```{r}
library(quantmod)
getSymbols('MSFT', src='yahoo')
y = Ad(MSFT[index(MSFT)>"2023-01-01",])

dy = diff(y)

arima(dy, order = c(0,0,0))
```


# Forecasting with Random Walks

Suppose that we know $y_0, y_1, ..., y_T$ and we want to forecast $y_{T+l}$ for some fixed $l>0$

-   Point forecast: the estimated $l$ step-ahead is

$$
\hat{y}_{T+l} = y_T + l\hat{\mu}_{c},
$$ where $\hat{\mu}_{c}$ is the estimated mean of the white-noise. $\hat{\mu}_{c}$ can be $\bar{c}$

$$\bar{c} = \frac{\epsilon_1 + \epsilon_2 + ...+\epsilon_T}{T}$$

-   The standard error of the forecast is $s_c\sqrt{l}$, where $s_c$ is the estimated standard deviation of $\sigma_c$,

$$
s^2_c = \frac{1}{n-1}\sum_{i=1}^{T} \big(\epsilon_i - \bar{c}\big)^2
$$

# 

### Example

You are given:

i)  The random walk model

$$
y_t =  y_0 + \epsilon_1 + \epsilon_2 + \epsilon_3 +...+\epsilon_t,
$$

where $\epsilon_i, (i = 1, 2,..., t)$ denote observations from a white noise process.

ii) The following ten observed values of $\epsilon_t$:

| t     | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   | 10  |
|:------|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|
| $y_t$ | 2   | 5   | 10  | 13  | 18  | 20  | 24  | 25  | 27  | 30  |

iii) $y_0 = 0$

Calculate the 9 step-ahead forecast, $\hat{y}_{19}$.

# 

# 

### Example

You are given:

i)  The random walk model

$$
y_t =  y_0 + \epsilon_1 + \epsilon_2 + \epsilon_3 +...+\epsilon_t,
$$

where $\epsilon_i, (i = 1, 2,..., t)$ denote observations from a white noise process.

ii) The following ten observed values of $\epsilon_t$:

| t     | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   | 10  |
|:------|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|
| $y_t$ | 2   | 5   | 10  | 13  | 18  | 20  | 24  | 25  | 27  | 30  |

iii) $y_0 = 0$

Calculate the standard error of the 9 step-ahead forecast, $\hat{y}_{19}$.

# 

We have $\epsilon_t = y_t -y_{t-1} \implies \epsilon_1, \epsilon_2, ..., \epsilon_{10} = 2,3,5,3,5, 2, 4,1, 2,3$

$$ \implies \bar{c} = \frac{\epsilon_1 + \epsilon_2 + ...+\epsilon_{10}}{10} = 3$$

$$
\implies s^2_c = \frac{1}{9}\sum_{i=1}^{10} \big(\epsilon_i - 3\big)^2 = 16/9
$$ Hence, the standard error is $s_c\sqrt{l} = \frac{4}{3}\sqrt{9} = 4$

