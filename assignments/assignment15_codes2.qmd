---
title: "Text Mining - Text Clustering"
format: 
  html: 
    toc: true
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

------------------------------------------------------------------------


### Datasets

- In this notebook, we will study a text dataset containing reviews from Amazon. The dataset can be downloaded below.

[Dataset](amazon_reviews.csv)


## Document Term Matrix

A Document Term Matrix (DTM) represents the relationship between terms and documents. It converts a text dataset into a numeric dataset. 

### Document Term Matrix - term frequency

```{r}
library(tidyverse)
library(tidytext)
library(tm)
library(wordcloud)
df <- read_csv("amazon_reviews.csv")

df <- df %>% 
  select(id, reviews.text) %>% 
  rename(document = id, 
         texts = reviews.text)

# create the DTM
df_tm <- df %>% 
  unnest_tokens(output = word, input = texts) %>% 
  anti_join(get_stopwords()) %>% 
  anti_join(tibble(word = c(letters, LETTERS, "oh", 'just', as.character(c(1:100)))))

word_freq <- df_tm %>% 
  group_by(document) %>% count(word, sort = TRUE)

df_dtm <- word_freq %>% 
  cast_dtm(document = document, term = word, n)

tm::inspect(df_dtm)
```
### Document Term Matrix - tf-idf

We can also convert a text dataset into numeric dataset where the entries are the tf-idf

```{r}
df_dtm <- weightTfIdf(df_dtm)
tm::inspect(df_dtm)
```

## Clustering

- Once the text dataset is converted into a numeric dataset, we could perform statistical or data mining techniques on the data.  In this section we will implement clustering technique after on the Document Term Matrix of a text dataset. 

- Since we want to cluster the terms/words, terms or words has to be the rows of the dataset to peform clustering.  Thus, we will need to transpose the dataset so that the terms are rows of the data. 


```{r}
# df_dtm <- removeSparseTerms(df_dtm, 0.5)
kmeans.data <- as.matrix(t(df_dtm))
kfit <- kmeans(kmeans.data, 3)
```


- Plot word cloud

```{r}
# plot word cloud
df %>%
  unnest_tokens(input = texts, output = word) %>% 
  anti_join(get_stopwords()) %>% 
  count(word, sort = TRUE) %>% 
  with(wordcloud(word, n, random.order = FALSE, 
                 max.words = 50, colors=brewer.pal(8,"Dark2")))
```

- Plot cluster 1

```{r}
# Plot cluster 
k = 1

cluster = names(kfit$cluster)[kfit$cluster==k]
cluster = as_tibble(cluster) %>% 
  rename(word = value)

cluster = word_freq <- df_tm %>% 
  count(word, sort = TRUE) %>% 
  inner_join(cluster, by = 'word')

library(wordcloud)
set.seed(2024)
cluster %>% with(wordcloud(word, n, max.words = 50, random.order = FALSE, rot.per = 0.35, 
    colors = brewer.pal(8, "Dark2")))
```

- Plot cluster 2

```{r}
# Plot cluster 
k = 2

cluster = names(kfit$cluster)[kfit$cluster==k]
cluster = as_tibble(cluster) %>% 
  rename(word = value)

cluster = word_freq <- df_tm %>% 
  count(word, sort = TRUE) %>% 
  inner_join(cluster, by = 'word')

library(wordcloud)
set.seed(2024)
cluster %>% with(wordcloud(word, n, max.words = 50, random.order = FALSE, rot.per = 0.35, 
    colors = brewer.pal(8, "Dark2")))
```

- Plot cluster 3

```{r}
# Plot cluster 
k = 3

cluster = names(kfit$cluster)[kfit$cluster==k]
cluster = as_tibble(cluster) %>% 
  rename(word = value)

cluster = word_freq <- df_tm %>% 
  count(word, sort = TRUE) %>% 
  inner_join(cluster, by = 'word')

library(wordcloud)
set.seed(2024)
cluster %>% with(wordcloud(word, n, max.words = 50, random.order = FALSE, rot.per = 0.35, 
    colors = brewer.pal(8, "Dark2")))
```


## Part of Speech

In this section, we analyze a text dataset by mapping the words into its part of speech (Noun, Verbs...)

- [Amazon Reviews Dataset](amazon_reviews.csv)

```{r}
library(tidyverse)
library(tidytext)
library(tm)
library(wordcloud)
df <- read_csv("amazon_reviews.csv")

df <- df %>% 
  select(id, reviews.text) %>% 
  rename(document = id, 
         texts = reviews.text)

stop_word2 = tibble(word = c(letters, LETTERS, "oh", 'just'))

df %>% 
    unnest_tokens(input = texts, output = word) %>% 
    count(word, sort = TRUE) %>% 
    anti_join(get_stopwords()) %>% 
    anti_join(stop_word2) %>% 
    inner_join(parts_of_speech) %>%                   # join POS
    count(pos) %>%                                    # count
    mutate(prop=n/sum(n)) %>% 
    slice_max(prop, n = 15) %>%
    ggplot()+geom_col(aes(y = pos, x = prop), position = 'dodge')

```


[Netflix Dataset](netflix_titles.csv)

```{r}
library(tidyverse)
library(ggplot2)
library(tidytext)
df <- read_csv('netflix_titles.csv')

df = df %>% 
  select(type, description) %>% 
  rename(texts = description,
         document = type)

stop_word2 = tibble(word = c(letters, LETTERS, "oh", 'just'))

df %>% 
    unnest_tokens(input = texts, output = word) %>% 
    group_by(document) %>% 
    count(document, word, sort = TRUE) %>% 
    anti_join(get_stopwords()) %>% 
    anti_join(stop_word2) %>% 
    inner_join(parts_of_speech) %>%                   # join POS
    count(pos) %>%                                    # count
    mutate(prop=n/sum(n)) %>% 
    slice_max(prop, n = 15) %>%
    ggplot()+geom_col(aes(y = pos, x = prop, fill =  document), position = 'dodge')
```

---